---
title: "Final Report for IMDb Movie Bias"
author: "Marie Hasegawa - `mhasegawa7045@floridapoly.edu`"
output: html_notebook
---


## Section 1: Introduction
```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
IMDB <- read_csv("https://raw.githubusercontent.com/reisanar/datasets/master/IMDB_movies.csv")
```
The box office industry is one of the biggest global markets in the entertainment industry. According to `IMDbPro`,the industry has a yearly average ` box office revenue` of around 11 to 14 million dollars and a yearly `total gross` of around 9 to 12 billion dollars.

The purpose of the project is to see how a movie's`genre`, `runtime`, `director`, and `actors` can affect the success of a movie and create bias ratings, which will be based on the given `rating`, `votes`, `revenue`, and `metascore`. This project will be using the `IMDB_movies.csv` dataset, which is available in this link, [IMDB_movies.csv](https://github.com/reisanar/datasets/blob/master/IMDB_movies.csv) and in `Section 2: Data Analysis`.

### Section 1.1: Index
* Section 1: Introduction
  * Section 1.1: Index
* Section 2: Data Analysis
  * Section 2.1: Director's Effect on Rating and Metascore
  * Section 2.2: Rating Vs Metascore
  * Section 2.3: Runtime's Effect on Rating and Metascore
  * Section 2.4: Rating's and Metascore's Effect on Revenue
* Section 3: Conclusion

## Section 2: Data Analysis

The dataset, `IMDB_movies.csv`, is a collection of popular movies rated on IMDb for the past decade. The data fields included are `Rank`, `Title`, `Genre`, `Description`, `Director`, `Actors`, `Year`, `Runtime (Minutes)`, `Rating`, `Votes`, `Revenue (Millions)`, and `Metascore`. `IMDB_movies.csv` was provided by Professor Rei Sanchez-Arias under his GitHub account, `reisanar`. The dataset only contains 1000 movies (rows) from 2006 to 2016, so movies past 2006 and from the 20th century will take no part in this analysis. 


### Section 2.1: Finding out how `ratings` and `metascore` are affected by who the  `actors` are in the movie by analyzing each `actor's` frequency of highly rated movies.

```{r}
num_movies_by_actors<-tally(group_by(IMDB,Actors), sort=TRUE) %>%
  head(n=10)
num_movies_by_actors
ggplot(data = num_movies_by_actors, mapping = aes(x = reorder(Actors, n), n)) +
  ggtitle("Actor's Movie Count (n) w/ Highest Ratings") +
  geom_bar(stat = "identity", color="black", fill="blue") + coord_flip()
IMDB_with_Act_tally <- IMDB %>%
      arrange(desc(Rating)) %>%
      select(Title, Director, Actors, Rating, Metascore) %>% 
      group_by(Actors) %>% 
      mutate(count_mov = n())
```
```{r}
avg_rating_Act_table<- IMDB %>% 
  group_by(Actors) %>%
  summarize(avg_rating=mean(Rating, na.rm=TRUE)) %>%
  arrange(desc(avg_rating)) %>%
  head(n=10)
ggplot(data = avg_rating_Act_table, mapping = aes(x = reorder(Actors, avg_rating), avg_rating)) + 
  geom_bar(stat = "identity", color="black", fill="pink") + coord_flip()
```













### Section 2.1: Director's Effect on Rating and Metascore

Ratings can be affected by who directed the movie and who starred in it. Directors and actors can create bias in movie's `ratings` that conflict with its `metascores`. This hypothesis will be tested by analyzing each `director's` and `actor's` frequency of highly rated movies in a data frame called, `num_movies_by_director`. This dataframe will be visualized in a Bar Chart called `Director's Movie Count (n) w/ High Ratings`, which `n` represents the number of movies and `reorder(Director, n)` lists the `Directors` who made the most movies.

Based on average ratings and highest frequency of movies, `Christopher Nolan` is the most frequent director with the highest ratings from his movies: `The Dark Knight`, `Inception	`, `Interstellar`, `The Prestige`, and `The Dark Knight Rises`.  


```{r}
num_movies_by_director<-tally(group_by(IMDB,Director), sort=TRUE) %>%
  head(n=10)
num_movies_by_director
ggplot(data = num_movies_by_director, mapping = aes(x = reorder(Director, n), n)) +
  ggtitle("Director's Movie Count (n) w/ Highest Ratings") +
  geom_bar(stat = "identity", color="black", fill="green") + coord_flip()
IMDB_with_Dir_tally <- IMDB %>%
      arrange(desc(Rating)) %>%
      select(Title, Director, Actors, Rating, Metascore) %>% 
      group_by(Director) %>% 
      mutate(count_mov = n())
```
```{r}
avg_rating_Dir_table<- IMDB %>% 
  group_by(Director) %>%
  summarize(avg_rating=mean(Rating, na.rm=TRUE)) %>%
  arrange(desc(avg_rating)) %>%
  head(n=10)
ggplot(data = avg_rating_Dir_table, mapping = aes(x = reorder(Director, avg_rating), avg_rating)) + 
    ggtitle("Director's Average Rating") +
  geom_bar(stat = "identity", color="black", fill="pink") + coord_flip()
```
```{r}
avg_meta_Dir_table<- IMDB %>% 
  group_by(Director) %>%
  summarize(avg_meta=mean(Metascore, na.rm=TRUE)) %>%
  arrange(desc(avg_meta)) %>%
  head(n=10)
ggplot(data = avg_meta_Dir_table, mapping = aes(x = reorder(Director, avg_meta), avg_meta)) + 
    ggtitle("Director's Average Metascore") +
  geom_bar(stat = "identity", color="black", fill="purple") + coord_flip()
```

















### Section 2.2: Rating Vs Metascore
`Ratings` and `Metascore` are not exclusively equivalent, since `Ratings` are made by ordinary people while `Metascores` are made by licensed critics. This idea will be explored in the dataframes---`RateVsMeta`, which is arranged in descending `Rating`, and `MetaVsRate`, which is arranged in descending `Metascore`. Let this project assume that a `Rating` of 10 is equivalent to a `Metascore` of 100.

The top 20 rated movies in the table, `RateVsMeta`, shows that five movies have shown very conflicting `Ratings` and `Metascores`: `The Intouchables`	(Rating=8.6; Metascore=57), `The Prestige`	(Rating=8.5;	Metascore=66), `Taare Zameen Par`	(Rating=8.5;	Metascore=42), `3 Idiots`	(Rating=8.4, Metascore=67), and `Inglourious Basterds`	(Rating=8.3,	Metascore=69). However, the top 20 movies with the highest `Metascores` in the dataframe, `MetaVsRate`, had only one movie, `Megan Is Missing`	(Rating=94	Metascore=4.9), that had a conflicting `Rating` and `Metascore`.

These observations prove that people and critics have different criteria for ranking a movie's quality, which can be further proven in the scatter plot, `Rating Vs Metascore Scatter Plot`. The scatter plot shows that many highly rated movies fall under the `Metascore` coordinate of the line, but movies that performed very well in the `Metascore` rarely fall under the `Ratings`. 
```{r}
RateVsMeta<-IMDB %>%
  select(Title, Rating, Metascore) %>%
  mutate(avg_rates=mean(Rating), avg_meta=mean(Metascore, na.rm=TRUE)) %>%
  arrange(desc(Rating))
RateVsMeta

MetaVsRate<- IMDB %>%
  select(Title, Metascore, Rating) %>%
  mutate(avg_meta=mean(Metascore, na.rm=TRUE), avg_rates=mean(Rating)) %>%
  arrange(desc(Metascore))
MetaVsRate

ggplot(data = RateVsMeta, aes(x = Rating, y = `Metascore`)) + 
  geom_point() +
  geom_smooth() +
  ggtitle("Rating Vs Metascore Scatter Plot") 


```














